---
title: "CERMBweather package introduction"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{introduction}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  echo = TRUE,
  eval = FALSE
)

dbpath <- "c:/michael/Rworkspaces/BOMdata/database/test.db"
if (file.exists(dbpath)) unlink(dbpath)

```

## Installing the package

The current version of the package can be installed from GitHub with the following R commands:

```{r eval = FALSE}

# If you don't already have the devtools package
install.packages("devtools")

devtools::install_github("mbedward/CERMBweather")

```

You will need the following packages installed:

  * DBI - general database functions
  * dbplyr - allows dplyr to be used with database tables
  * dplyr - functions to work with data frames
  * pool - provides a pool of database connections
  * RSQLite - specific functions for SQLite databases
  * stringr - functions to query and manipulate character strings
  
These should be included as part of the install from GitHub but if not, the following command will install the current version of each:

```{r eval = FALSE}

install.packages(c("DBI", "dbplyr", "dplyr", "pool", "RSQLite", "stringr"))

```


## Functions to work with BOM zip files

There are several functions to work with zip files of synoptic or AWS (ie. hourly or half-hourly) weather data as received from BOM. The zip files contain CSV format data files, one per weather station.

### Summary of zip file contents

```{r}

library(CERMBweather)
library(dplyr, warn.conflicts = FALSE)

# Edit these paths for your system
#DIR <- "s:/Biosci Bushfires/CERMB_LIBRARY/DATA/WEATHER/BOM_updates/"
DIR <- "c:/michael/Rworkspaces/BOMdata"

SYNOPTIC <- file.path(DIR, "updates", "DS106_Clarke_synoptic_20180521.zip")
AWS <- file.path(DIR, "updates", "DS106_Clarke_halfhourly_20180521.zip")


# list the weather stations with non-empty data sets and 
# display the first few rows
stns <- bom_zip_summary(SYNOPTIC)
head(stns)

```

```{r}

# Find any weather stations in the zip file that have
# empty data sets
bom_zip_summary(SYNOPTIC, include = "empty")

```

### Retrieve station data directly

The function `bom_station_data` extracts data for one or more weather stations from a zip file and makes it available directly in your R workspace. By default, the function returns a list of data frames. Each data frame contains a subset of the BOM raw data fields (e.g. 'quality' fields are omitted) with more concise column names. 


```{r}

# Load data for three specified stations
res <- bom_zip_data(SYNOPTIC, stations = c(3080, 14840, 200790))

# List element(s) are named by station number, formatted as a
# six charcter string
names(res)

```

We can access a single data frame with the usual R list operations. Any of the following will retrieve the second data set (for station 14840):

```{r}

dat <- res[[2]]
dat <- res[["014840"]]
dat <- res$`014840`

```

You can also use the optional `out.format` argument to return data for multiple stations as a single data frame.

```{r}

dat <- bom_zip_data(SYNOPTIC, stations = c(3080, 14840, 200790), 
                    out.format = "single")

dim(dat)

# number of records for each stations
table(dat$station)

# first few records
head(dat)

```


## Database functions

Most of the time you will want to transfer weather station data from zip files, directories or individual files into a database (e.g. a central copy on the share drive) rather than load them directly into your R workspace. The package uses [SQLite](https://www.sqlite.org) as the database back-end. All data are stored in a single file which can be moved or copied as desired. SQLite databases have full support for SQL and can be accessed from a wide range of applications. 

In R, tables in a SQLite database can be queried in much the same way as when working with data frames using the `dplyr` and `dbplyr` packages. They can also be queried from R using SQL commands with the `DBI` package. The `CERMBweather` package provides functions that hide the messy detail for the most common tasks.


### Creating a database

The code below creates a new database with a specified path and file name (SQLite does not require any particular file name convention) containing tables for synoptic and AWS data.

```{r}

# Create a new database with the required tables
DB <- bom_db_create("c:/michael/Rworkspaces/BOMdata/database/test.db")

```

The object `DB` returned by the function is a database connection pool (an object of class `Pool` defined in the `pool` package). It serves as a connection or proxy for the database that can be used to import and retrieve data.

### Opening an existing database

You can access an existing database from R with the `bom_db_open` function. This function checks that the file exists and that it contains database tables for AWS and synoptic data. By default it returns a read-only connection that allows you to query data but not modify the database itself. You only need to do this once, at the start of an R session.

```{r eval=FALSE}

# Open the database in read-only mode
DB <- bom_db_open("c:/michael/Rworkspaces/BOMdata/database/test.db")

```


When you need a database connection that allows new data to be imported into the database you supply an extra argument to the `bom_db_open` function. 

```{r eval = FALSE}

DB <- bom_db_open("c:/michael/Rworkspaces/BOMdata/database/test.db", readonly = FALSE)

```



### Importing data from zip files

In the code below, `SYNOPTIC` and `AWS` are the file paths defined earlier for BOM zip files.

Import data from the synoptic zip file:

```{r}

# Open read-write connection to the database
DB <- bom_db_open("c:/michael/Rworkspaces/BOMdata/database/test.db", readonly = FALSE)

# Import data from zip file containing synoptic data files for weather stations
bom_db_import(DB, SYNOPTIC)

```


Import data from the AWS zip file:

```{r}

bom_db_import(DB, AWS)

```

The import function silently ignores any weather station records that are already present in the database, so if we repeat the last import we should see 0 records imported:

```{r}

bom_db_import(DB, AWS)

```


### Importing data from files in a directory

When passed a directory path rather than a zip file path, the `bom_db_import` function will import data from all, or a specified subset, of the weather station data files in that directory.

```{r}

path <- file.path(DIR, "rawfiles", "Synoptic")

# DB is a read-write database connection (see earlier examples)
bom_db_import(DB, path)

```


### Importing data from an individual file

The `bom_db_import` will also work with an individual file.

```{r}

path <- file.path(DIR, "rawfiles", "AWS", "HM01X_Data_200284_999999999515424.txt")

# DB is a read-write database connection (see earlier examples)
bom_db_import(DB, path)

```

### Closing the database

At the end of an R session it is a good idea to close the database connection and delete the connection. Nothing terrible will happen if you fail to do this, but a connection object saved from a previous session will not work.

```{r}

bom_db_close(DB)

```



### Querying the database

Once we have some data in the database we can extract or summarize data in a variety of ways. The package provides functions to summarize the contents of the database.

Count synoptic and AWS records:

```{r}

# Open a database connection at the start of your R session
DB <- bom_db_open("c:/michael/Rworkspaces/BOMdata/database/test.db")

bom_db_summary(DB)

```

Count records by station:

```{r}

dat <- bom_db_summary(DB, by = "station")

head(dat, 3)
tail(dat, 3)

```

Arbitrary queries can be done using `dplyr` package functions and `tbl` objects which act as proxies for database tables, allowing them to be treated like data frames. You can either create these on the fly as part of a pipeline of dplyr commands, or store a reference to the table as in the example below. The stored `tbl` object can then be used repeatedly as long as the associated database connection remains open.

```{r}

# Query synoptic data and find the maximum temperature recorded 
# for each weather station

# Get a dplyr `tbl` object for the Synoptic table
tsynoptic <- bom_db_synoptic(DB)

# Find maximum temperature for each station
dat <- tsynoptic %>%
  # construct the query
  group_by(station) %>%
  summarize(maxtemp = max(temperature, na.rm = TRUE)) %>%
  filter(!is.na(maxtemp)) %>%
  
  # execute the query
  collect()

# Display results
plot(density(dat$maxtemp), 
     xlab = "temperature", ylab = "density",
     main = "Max temperatures")

```

The sequence of dplyr commands in the above query is the same as would be used with an ordinary data frame except for the last `collect` function. This tells dplyr to execute the query on the database and retrieve the results. Up to that point dplyr has simply constructed a query ready to use. Sometimes it is convenient to construct one or more queries but delay their evaluation until later, perhaps conditional on other variables.

```{r}

# Construct a dplyr query
qry <- tsynoptic %>%
  group_by(station) %>%
  summarize(maxtemp = max(temperature, na.rm = TRUE)) %>%
  filter(!is.na(maxtemp))
  
# Printing the query will cause dplyr to get the first few rows of the result
qry

```

```{r}

# Use collect() to retrieve all results
dat <- collect(qry)
  
```


Behind the scenes, dplyr is constructing an SQL query to submit to the database. You can examine the SQL statements with the dplyr `show_query` function.

```{r}

show_query(qry)

```


You can also submit your own SQL queries to the database directly. Note that for complex queries with variable parameters you will probably want to use the `glue_sql` function from the `glue` package to construct the query rather than the base R `paste` or `sprintf` functions.

```{r}

qry <- paste(
  "SELECT station, MAX(temperature) AS maxtemp FROM SYNOPTIC",
  "GROUP BY STATION",
  "HAVING NOT(maxtemp IS NULL)")

dat2 <- DBI::dbGetQuery(DB, qry)

```

This query produces the same result as the earlier dplyr query. 

```{r}

all.equal(dat, dat2)

```

```{r include=FALSE, eval=TRUE}

bom_db_close(DB)

```

